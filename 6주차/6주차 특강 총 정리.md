## 이활석님 특강
---
- 예전에도 계속 들어왔던 말이지만, 실제 AI 모델을 서빙까지 하는데 있어 AI modeling이 차지하는 비율은 그렇게 크지 않음. 실제로는 데이터 수집이나 serving환경 구축단계에서도 많은 리소스(금전적,시간적)를 소모하게 됨.

- 새로운 것에 빠르게 적응할 수 있어야 하며 이를 두려워하지 말아야 한다. 회사 (특히 AI 분야)에서 선호하는 인재상은 러닝커브가 좋은 사람이다.

- 그리고 러닝 커브를 좋게 만들기 위해서는 기본기를 다지는 것이 역시나 중요하다. 베이스라인이 좋은 사람은 뭐든지 빠르게 습득 할 수 있다.

- 몇 년후를 생각해보면, 단순 AI 모델링 외 다른 것도 할 줄알아야 경쟁력이 생긴다.
    - 지금 당장은 모델링하는 사람조차도 부족한 상황이지만, 나중에는 모델링하는 사람이 충분히 많아질 수 있고 또한 AutoML 등이 발전하고 있기 때문에 자신만의 차별화된 역량을 갖추어야 한다.
    - 물론 그렇다고 모델링 스킬을 소홀히 해서는 안되고 우선 순위를 잘 파악한 상태에서 여러가지를 시도 하자.

- AI 트렌드 캐치를 위해 많은 커뮤니티를 참고할 수 있는데 Tensorflow KR, 트위터, reddit, 뉴스레터등이 해당 된다.

- 항상 기술 변화에 민감해야 한다. 남들보다 한 박자 빠르게 뛰어 들 수 있는 욕기나 혜안, 그리고 무엇보다도 새로운 기술이 나타났을때 비즈니스에서 쓸모가 있는지 파악할 수 있는 역량 등도 중요하다. 이러한 역량을 키우기 위한 습관 1순위가 트렌드를 항상 파악하고 있는 것이다.

- 나름의 방향을 정하는 것이 중요하다. 사실 지금 이 분야에서 현업에 있는 사람들도 객관화된 로드맵 같은 것 없이 공부하고있다. 이러한 것들을 스스로 설계해야한다.

## 박은정님 특강

- 기본기를 탄탄히 하자. 최신 모델을 아는 것도 중요하지만 그것보다도 기본적으로 베이스 지식들을 알고 있어야 한다.
    - 예를 들어 learning rate, regulariation 등에 대해 대충 뭐하는건지만 알고 있지 말고 이들을 최적화시키는 여러가지 방법에 대해 고민해보고 찾아보자. 여기서부터 모든 것이 파생돼서 나오는 건데 이런것들을 모른채로 최신 기술들만 알려고 하면 안된다.
    - 기술의 기본기를 쌓기 위해 어떤 개념이 있으면 그 개념의 근복적인 시작점에 대해 고민해 보자.


- 기초 과목에 대한 지식도 중요하지만 실전 경험 역시 매우 중요하다. Kaggle이나 데이콘 등에 꾸준히 참여하려고 하자.
- 자신한테 맞는 분야를 찾기 위해 각자에게 맞는 방법이 있다. 오픈소스를 뜯어보고 contribution을 하거나 Kaggle에 참여하거나 논문을 재구현해보거나 여러가지 방법론이 있으니 직접 해보자.

- 한 분야에만 너무 몰두하는 것도 좋지만, 기회가 왔을 때 빠르게 전환하는 것도 중요한 것 같다.
    - 물론 한 분야를 파서 더 성공할 수도 있는 것이지만, 지금까지 쌓아온 것이 아깝다고 기회가 왔을때 그걸 버리는 일은 없도록 하자.
    - 항상 기회가 왔을 때 그쪽으로의 전환에 대해 두려워 하지 말자

- 뭘 좋아하는지 모르겠으면 뭘 싫어하는지를 먼저 생각해보자.
- 직접 모데를 짜보고 배포까지 해보는 훈련을 하자.

## 김상훈님 특강

- Kaggle 등 경진대회에 꾸준히 참여하면 성과가 나오지 않더라도 실력 향상에 큰 도움이 될 수 있다.
- 공부 목적에서는 kaggle notebook만 잘 활용하더라도 꽤 좋은 공부를 할 수 있다.
- 하이퍼 파라미터는 어떤 데이터를 다루느냐에 따라 조절할 수 있는 반경이 다르다. 다만 이것도 많이 참여하다 보면 감각이 생긴다.


## 이준엽님 특강
- 뭐든지 완성을 하려고 하자. 쉽게 지칠수 있기 때문이다. 너무 퀄리티를 높이려고 하지 말고 시작 단계에서 너무 욕심을 부리지 말자.
- 시작하는 단계에서는 너무 깊이 알려고 하거나 모든걸 이해하려고 하지 말자. 역시 쉽게 지칠 수 있기 때문이다. 만약 한 30%정도를 조금 봐선 도저히 모르겠다면 그 부분은 나중의 나에게 미뤄도 된다.
- 풀스택을 지향하더라도 자신의 메인 분야를 절대 놓치면 안된다. 서브 분야들은 내가 원하는걸 어느 정도 찾아보면서 구현할 수 있을 정도 까지만 스택을 쌓으면 된다.

## 박성준 님 특강

- ELMo 모델에 대하여 이전에 살펴보지 않았는데, bidirectional Language Model의 일종으로, 워드 임베딩시 앞쪽의 정보만 고려하고 뒤쪽의 정보는 고려하지 못한 다는 단점을 해소한 방법이다.
    - 이전에 NLP 다룰 때 잠깐 이런 방법이 있다고만 얘기하고 넘어갔었는데, ELMo가 바로 그것 중 하나다.
    - 양방향 RNN과는 개념상으로 아예 다르다.
    - ELMo로 만든 벡터를 기존 워드 임베딩(Word2Vec,GloVe)과 연결시켜 ELMo representation을 만들어 이를 최종적인 워드 임베딩으로 활용할 수 있다.
- NLP는 BiLM 이후 pre-training에 집중하게 되었다. 즉, 언어 모델만 잘 만들면 모든 task에 사용 가능하다는 점을 발견한 것이다.

- 언어 모델 평가를 위해 GLUE(General Language Understanding Evaluation) 벤치마크를 통상적으로 활용한다. GLUE의 척도는 아래와 같다. (SQuAD는 GLUE에 포함되지 않지만, 대표적인 NLP 모델 평가 척도 중 하나이다)
    - Quora Question Pairs (QQP, 문장 유사도 평가)
    - Question NLI (QNLI, 자연어 추론)
    - The Stanford Sentiment Treebank (SST, 감성 분석)
    - The Corpus of Linguistic Acceptability (CoLA, 언어 수용성)
    - Semantic Textual Similarity Benchmark (STS-B, 문장 유사도 평가)
    - Microsoft Research Paraphrase Corpus (MRPC, 문장 유사도 평가)
    - Recognizing Textual Entailment (RTE,자연어 추론)
    - SQAUD 1.1/2.0 (질의응답)
    - MultiNLI Matched (자연어 추론)
    - MultiNLI Mismatched (자연어 추론)
    - Winograd NLI (자연어 추론)

- 그 외 많은 언어들에도 그만의 평가 척도(프랑스어, FLUE / 중국어, CLUE)가 있으며, KLUE(Korean)는 현재 개발중이라고..
