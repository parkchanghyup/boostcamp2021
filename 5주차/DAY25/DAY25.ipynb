{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래프 신경망\n",
    "\n",
    "---\n",
    "변환식 임베딩 방법의 단점들을 극복한 귀납식 임베딩 방법에선느 출력으로 임베딩 벡터가 아닌 인코더를 얻는다. 그래프 신경망(GNN)은 대표적인 귀납식 임베딩 방법이다\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프 신경망 구조\n",
    "---\n",
    "- 그래프 신경망은 **이웃 정점들의 정보를 집계하는 과정을 반복**하여 `임베딩`을 얻는다.\n",
    "- 예시에서 `대상 정점`의 임베딩을 얻기 위해 이웃들 그리고 이웃의 이웃들의 정보를 집계한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![구조](구조.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 집계 단계를 층(Layer)이라고 부르고, 각 층마다 임베딩을 얻는다.\n",
    "\n",
    "- 각층에서는 **이웃들의 이전 층 임베딩을 집계하여** 새로운 임베딩을 얻는다.\n",
    "- 0번층, 즉 입력 층의 임베딩으로는 `정점의 속성` 벡터를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![구조](구조2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![구조](구조3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 서로 다른 대상 정점간에도 **층 별 집계 함수는 공유** 한다.\n",
    "![구조](구조4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 집계 함수는 **(1) 이웃들 정보의 평균을 계산**하고 **(2) 신경망에 적용** 하는 단계를 거친다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![구조](구조5.PNG)\n",
    "![구조](구조6.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **마지막 층에서의 정점 별 임베딩**이 해당 정점의 `출력 임베딩` 이다.\n",
    "![구조](구조7.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프 신경망의 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그래프 신경망의 `학습 변수(Trainable Parameter)는 **층 별 신경망의 가중치** 이다\n",
    "\n",
    "![구조8.PNG](구조8.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 먼저 `손실함수`를 결정한다. 정점간 거리를 **보존**하는것을 목표로 할 수 있다.\n",
    "\n",
    "<br/>\n",
    "변환식 정점 임베딩에서 처럼 그래프에서의 정점간 거리를 **보존**하는 것을 목표로 할 수 있다.\n",
    "만약, 인접성을 기반으로 유사도를 정의한다면, `손실 함수는 다음과 같다.\n",
    "![학습](학습.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **후속 과제의 손실함수를 이용한 End-to-End 학습도** 가능하다.\n",
    "![학습](학습2.PNG)\n",
    "<br/>\n",
    "\n",
    "이 경우 분류기의 손실함수, 예를 들어 교차 엔트로피(Cross Entropy)를 전체 프로세스의 손실함수로 사용하여 End-to-End 학습을 할 수 있다.\n",
    "![학습](학습3.PNG)\n",
    "<br/>\n",
    "![학습](학습4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프 신경망의 End-to-End 학습을 통한 분류는, 변환적 정점 임베딩 이후에 별도의 분류기를 학습하는 것 보다 정확도가 대체로 높다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그래프 신경망의 학습에는 꼭 모든 정점을 활용할 필요는 없다.\n",
    "![학습](학습5.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 오차역전파를 통해 신경망의 학습 변수들을 학습\n",
    "- 일부 대상 정점을 골라서 훈련 가능 파라미터를 학습하여(층별로 공유, 층간은 상이한)다른 정점(학습에 포함되지 않은 or 새로 추가된)에 활용할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프 신경망의 활용\n",
    "- 다른 그래프에도 적용 가능. 단, 같은 도메인(단백질 1종,2종 등등)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프 신경망 변형\n",
    "\n",
    "### 그래프 합성곱 신경망(GCN)\n",
    "---\n",
    "- 기존 집계 함수와 GCN의 집계 함수의 가장 큰 차이점\n",
    "    - 기존 집계 함수 : $B_kh_v^{k-1}$ 현재 집계 되고 있는 정점 v의 이전 레이어 k-1의 임베딩 $h_v^{k-1}$을 별도의 $B_k$라는 신경망을 이용하여 합계 해줬음(기존)\n",
    "\n",
    "    - GCN : 기존 $W_k$ 신경망을 같이 사용해서 현재 정점 $v$까지 함께 평균 냄!\n",
    "\n",
    "    +) $\\frac{1}{\\sqrt{|N(u)||N(v)|}}$(정규화 방법 변화) : 기존 v의 연결성 $|N(v)|$만 사용했으나, u와 v 연결성 $|N(u)|, |N(v)|$의 기하평균(${|N(u)||N(v)|}^\\frac{1}{2}$)을 사용하고 있음!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphSAGE\n",
    "---\n",
    "- 이전 레이어의 임베딩을 받아옴 {$h_u^{k-1}$, ,,,,}, `AGG`, 집계, $W_k$ 신경망 통과\n",
    "- $B_kh_v^{k-1}$ : 자기 자신의 이전 레이어의 임베딩을 신경망에 통과한 값\n",
    "- 위 둘을 더하는 것이 아니라(기존) concatenation 함\n",
    "- `AGG` : 다양한 옵션 사용 가능!(평균 이외에도 pool, LSTM)\n",
    "- Pool : 원소별 최대값을 output\n",
    "- LSTM : 이웃들의 정보를 LSTM의 입력으로! 넣어서 그 결과를 사용\n",
    "\n",
    "    - $\\pi$ : 이웃들의 임베딩을 가져와서 순서를 섞은 다음에 LSTM에 넣어준다는 뜻임(그래프의 이웃들은 순서가 있는 sequential한 정보가 아니므로 무작위화 해주는듯?)\n",
    "\n",
    "- 차이점\n",
    "\n",
    "    - 집계 방법을 여러개 활용할 수 있다\n",
    "\n",
    "    - 위 집계 결과를 신경망 통과 시킨 것과, 자기 자신의 이전 층에서의 임베딩을 신경망에 통과한 값을 concat시킨다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 합성곱 신경망과의 비교\n",
    "---\n",
    "### 4.1 합성곱 신경망과 그래프 신경망의 유사성\n",
    "\n",
    "- 합성곱은 이웃 픽셀의 정보를 집계 -> 이웃 수가 균일\n",
    "- 그래프는 대상 정점을 어디로 두냐에 따라 집계하는 이웃 수가 다름\n",
    "\n",
    "### 4.2 합성곱 신경망과 그래프 신경망의 차이\n",
    "\n",
    "- i라는 행의 위 i-1 아래 i+1 행들은 i와 직접적인 연관이 있지 않고, 행렬 순서가 임의로 결정되는 경우가 많음 -> 이는 이웃을 의미하는 것도 아님!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프 신경망이란 무엇일까 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
